<!DOCTYPE html>
<html lang="en" style="height:100%">

<head>
    <meta charSet="UTF-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="description" content="Artificial intelligence with Mihok from TorontoJS, building on basic knowledge we will discover and build Neural Networks from scratch to get a better understanding of how they work." />
    <title>JS Workshop</title>
    <script type="text/javascript" src="helpers/manifest.lib.js"></script>
    <script type="text/javascript" src="helpers/math.lib.js"></script>
    <script type="text/javascript" src="helpers/data.lib.js"></script>
</head>

<body>
  <script type="text/javascript" src="helpers/renderers.lib.js"></script>
  <script type="text/javascript">


	function Sigmoid ( x ) 
	{
  		return 1 / (1 + Math.exp((-x)));
	}

	function DerivSigmoid ( x ) 
	{
  		let fx = Sigmoid(x);
  		return fx * (1 - fx);
	}



	// Shared variable names to reference information
	// only used as indexes for arrays
	const H1 = 0; // array index for neuron 1
	const H2 = 1; // array index for neuron 2
	const O1 = 2; // array index for output 1


	// only used as indexes for arrays
	const W1 = 0; //(INDEX ONLY) -- HIDDEN LAYER 1 NEURON 1 WEIGHT 1
	const W2 = 1; //(INDEX ONLY) -- HIDDEN LAYER 1 NEURON 1 WEIGHT 2
	const W3 = 2; //(INDEX ONLY) -- HIDDEN LAYER 1 NEURON 2 WEIGHT 1
	const W4 = 3; //(INDEX ONLY) -- HIDDEN LAYER 1 NEURON 2 WEIGHT 2
	const W5 = 4; //(INDEX ONLY) -- OUTPUT LAYER 1 NEURON 1 WEIGHT 1
	const W6 = 5; //(INDEX ONLY) -- OUTPUT LAYER 1 NEURON 1 WEIGHT 2

	// only used as indexes for arrays
	const I1 = 0;
	const I2 = 1;


    //----------------------------------------------------------------------
    class Network
	{
		// Network's fields
		// Biases
		biases = [
			0, // bias1 for hidden layer1
			0, // bias2 for hidden layer2
			0, // bias3 for output
		];

		// Weights
		weights = [0,0,0,0,0,0];

		lossFn = function (a, p) { throw new Error('not implemented'); };

		derivFn = function (a, p) { throw new Error('not implemented'); };


		// Hidden layer
		hidden = [];

		// Output layer
		output;

		//------
		constructor(weights = [], biases = [] , activatorFn , derivFn,  lossFn)
		{
			this.weights = weights;
			this.biases  = biases;
			this.derivFn = derivFn;
			this.lossFn  = lossFn;

			//splits the weights into 3 different arrays 
			//  note: W1,W2,W3,W4,W5,W6 are only being used here as index for 'this.weights' array 
			const h1Weights = [ this.weights[W1] , this.weights[W2] ];
			const h2Weights = [ this.weights[W3] , this.weights[W4] ];
			const o1Weights = [ this.weights[W5] , this.weights[W6] ];

			//hidden layer
			this.hidden = [
				new Neuron(h1Weights , this.biases[H1], activatorFn),
				new Neuron(h2Weights , this.biases[H2], activatorFn),
			];			

			// output neuron
			this.output = new Neuron(o1Weights, this.biases[O1], activatorFn, );
		} // end of constructor
		//------
	  
		//------
		// ** add something here
		// train() will receive input data and compare its calculations against the expected result





		//---------------------------------------------------------------
		// ##############################################################
		// NOT TESTED - START
		// ##############################################################
	
		// train() takes in a set of data to train on, and corrisponding answers 
	  	train (data = [], answers = [], iterations = 1000, rate = 0.1) 
	  	{
			let lossData = [];
	      	let lossSum = 0;
	      	let lossCount =0;

		    // We'll iterate over the data several times to adjust the weights 
			for (let i = 0; i < iterations; i += 1) 
		    {
		    	for (let d in data) 
		    	{

		      		//------------------------------------------------------------------
		        	// Get our individual neuron data to calculate things

		        	// Calculate our 1st hidden layer neuron
		        	let h1Sum = this.hidden[H1].sum(data[d]);
		        	let h1 = this.hidden[H1].activatorFn(h1Sum);

		        	// Calculate our 2nd hidden layer neuron
		        	let h2Sum = this.hidden[H2].sum(data[d]);
		        	let h2 = this.hidden[H2].activatorFn(h2Sum);

		        	// Calcualte our output layer neuron
		        	let o1Sum = this.output.sum([h1, h2]);
		        	let o1 = this.output.activatorFn(o1Sum);

		        	// Here is the networks current prediction
		        	let pred = o1;
		        	//------------------------------------------------------------------

		        	//General formula: ∂Loss/∂weight_1 = ∂Loss/∂Y_pred * ∂Y_pred/∂h1 * ∂h1/∂weight_1

		        	//------------------------------------------------------------------

		        	// Now we'll calculate an adjustment to the weights with partial
		        	// derivatives to improve that prediction based on the actual answers.
		        	// The formula we use is the following,
		        	//
		        	// ∂L/∂wN = ∂L/∂pred * ∂pred/∂wN
		        	//
		        	// Which will give us a value that we can apply against our learning
		        	// rate to adjust a particular weight
		        
		        	// ∂L/∂pred = -2*(answer - prediction);
		        	let pLpO1 = 2 * ( pred - answers[d] ); 		// STEP 1


		        	// Lets do our backpropagation to calculate the rest

		        	//------------------------------------------------------------------
		        	// OUTPUT NEURON


		        	// ∂pred/∂h1   -- pred/input -- step 2
		        	let pO1pH1 = this.weights[W5] * Math.derivSigmoid(o1Sum);		// STEP 2
		        	// ∂pred/∂h2  -- pred/input -- step 2
		        	let pO1pH2 = this.weights[W6] * Math.derivSigmoid(o1Sum);		// STEP 2


		        	// ∂pred/∂w6   -- input/wei -- step 3
		        	let pO1pW6 = h1 * Math.derivSigmoid(o1Sum);		// STEP 3
		        	// ∂pred/∂w5   -- input/wei -- step 3
		        	let pO1pW5 = h2 * Math.derivSigmoid(o1Sum);		// STEP 3

		        	// ∂pred/∂b3 <--- this comment might be wrong
		        	let pO1pB3 = Math.derivSigmoid(o1Sum);			// STEP 3 (?)




		        	//------------------------------------------------------------------

		        	// Hidden Neurons
		        	//   NEURON 1
		        	// ∂h1/∂w1   -- input/wei
		        	let pH1pW1 = data[d][I1] * Math.derivSigmoid(h1Sum);		// STEP 3
		        	// ∂h2/w2   -- input/wei
		        	let pH1pW2 = data[d][I2] * Math.derivSigmoid(h1Sum);		// STEP 3
		        	// ∂h1/b1   --
		        	let pH1pB1 = Math.derivSigmoid(h1Sum);						// STEP 3

		        	//   NEURON 2
		        	// ∂h2/w3   -- input/wei
		        	let pH2pW3 = data[d][I1] * Math.derivSigmoid(h2Sum);		// STEP 3
		        	// ∂h2/w4   -- input/wei
		        	let pH2pW4 = data[d][I2] * Math.derivSigmoid(h2Sum);		// STEP 3
		        	// ∂h2/b2   -- 
		        	let pH2pB2 = Math.derivSigmoid(h2Sum);						// STEP 3

		        	// STOCHASTIC GRADIENT DESCENT
		        	// Set our new weights and biases in our network so we remember them
		        	this.weights[W1] -= rate * (pLpO1 * pO1pH1 * pH1pW1); // = weight1 - rate * ( ∂Loss/∂O1_pred * ∂O1_pred/∂h1_pred * ∂h1_pred/∂weight1 )
		        	this.weights[W2] -= rate * (pLpO1 * pO1pH1 * pH1pW2); // = weight2 - rate * ( ∂Loss/∂O1_pred * ∂O1_pred/∂h1_pred * ∂h1_pred/∂weight2 )
			       
		        	this.weights[W3] -= rate * (pLpO1 * pO1pH2 * pH2pW3); // = weight3 - rate * ( ∂Loss/∂O1_pred * ∂O1_pred/∂h2_pred * ∂h2_pred/∂weight3 )
		        	this.weights[W4] -= rate * (pLpO1 * pO1pH2 * pH2pW4); // = weight4 - rate * ( ∂Loss/∂O1_pred * ∂O1_pred/∂h2_pred * ∂h2_pred/∂weight4 )
			       
		        	this.weights[W5] -= rate * (pLpO1 * pO1pW5);		  // = weight5 - rate * ( ∂Loss/∂O1_pred * 					   ∂O1_pred/∂weight5 )
		        	this.weights[W6] -= rate * (pLpO1 * pO1pW6);		  // = weight6 - rate * ( ∂Loss/∂O1_pred * 					   ∂O1_pred/∂weight6 )

		        	this.biases[H1] -= rate * (pLpO1 * pO1pH1 * pH1pB1);  // = bias1   - rate * ( ∂Loss/∂O1_pred * ∂O1_pred/∂h1_pred * ∂h1_pred/∂bias1   )
		        	this.biases[H2] -= rate * (pLpO1 * pO1pH2 * pH2pB2);  // = bias2   - rate * ( ∂Loss/∂O1_pred * ∂O1_pred/∂h2_pred * ∂h2_pred/∂bias2   )
		        	this.biases[O1] -= rate * (pLpO1 * pO1pB3);           // = bias3   - rate * ( ∂Loss/∂O1_pred * 					   ∂O1_pred/∂bias3   )


		        	// Now let's update our weights and biases to minimize loss
		        
		        	//-------------------
		        	// Output Neuron
		        	// Update our ouput neuron to reflect the new weights
			        this.output.weights = [
			        	this.weights[W5],
			        	this.weights[W6],
			        ];

		        	this.output.bias = this.biases[O1];
		        	//-------------------


		        	//-------------------
		        	// Hidden Layer Neuron #2
		        	// Update our neuron to reflect the new weights
		        	this.hidden[H2].weights = [
		          		this.weights[W3],
		          		this.weights[W4],
		        	];

		        	this.hidden[H2].bias = this.biases[H2];
		        	//-------------------

		        	//-------------------
		        	// Hidden Layer Neuron #1
		        	// Update our neuron to reflect the new weights
		        	this.hidden[H1].weights = [
		          		this.weights[W1],
		          		this.weights[W2],
		        	];

		        	this.hidden[H1].bias = this.biases[H1];
		        	//-------------------
		      	} // END OF for (let d in data) 




		      	//---------------------------------------------------------
		      	// Finally lets calculate our loss and output it for sanity
		      	if (i % 10 === 0) // every 10th training loop
		      	{
		        	// Generate an array of the output of our network at this time for each
		        	// row of data, then 
		        	let currentPrediction = []; // prediction is an array of floating point variables
		        	data.forEach((row) => // row is like [1,-1] or [0,1] or [2,3]
		        	{
		          		currentPrediction.push( this.query(row) ); // the result being inserted is something like this: 0.9467883893414601
		        	}, this);

		        	//the answers will be either 0 or 1, and the predictions will be like 0.9467883893414601
		        	let loss = this.lossFn(answers, currentPrediction); //usually Math.meanSquaredError

		        	lossData.push(loss);

		        	console.log(`iteration #${i}, loss: ${loss}`);

		        	lossSum += loss;
		        	lossCount++;

		        	// if( (lossSum/lossCount) < 0.001 ) //use this to trigger a pre-defined exit point
	        		// {
	        		// 	return;
	        		// }
		      	}
		      	//---------------------------------------------------------

		    } // END OF for (let i = 0; i < iterations; i += 1) 

		    console.graph(lossData);
		} // END OF train (data = [], answers = [], iterations = 1000, rate = 0.1) 
  
		//---------------------------------------------------------------
		// ##############################################################
		// NOT TESTED - START
		// ##############################################################
		
		//---------------------------------------------------------------


		//------
		// run() takes in inputs for a single run of the network, typically done after
		// it has been trained
		query(inputs = [])
		{
			let hiddenLayerOutput = [];
			for(let i in this.hidden) //hidden layers of neurons
			{
				//feed input to the hidden layer (namely feed input to neuron_1 and neuron_2)
				// and each neuron in the hidden layer will produce an output, which is stored (push)
				// into the 'hiddenLayerOutput' array
				hiddenLayerOutput.push(this.hidden[i].activate(inputs));
			}

			//finally feed the output from the hidden layer to the output layer
			return this.output.activate(hiddenLayerOutput); // output layer of neurons - last layer
		} //end of query
		//------


	} // end of class Network
    //----------------------------------------------------------------------


    //----------------------------------------------------------------------
    class Neuron
    {
		bias;
		weights;
		activatorFn = function(x){ throw new Error('not implemented'); };
		derivFn = function(x){ throw new Error('not implemented'); };

		//------
		//constructor(weights = [], bias = 0, activatorFn, derivFn)
		constructor(weights = [], bias = 0, activatorFn)
		{
			this.weights = weights;
			this.bias = bias;
			this.activatorFn = activatorFn;
			//this.derivFn = derivFn;
		} // end of constructor
		//------

		//------
		sum (inputs = [])
		{
			let buffer = [];
			let output = 0;

			//the general formula for this sum function is
			// ( V1*W1 + V2*W2 + ... + Vn*Wn ) + BIAS

			// weighing the inputs
			for(let i in inputs)
			{
				buffer[i] = inputs[i] * this.weights[i];
			}

			//sum
			for(let i in buffer)
			{
				output += buffer[i];
			}

			output += this.bias;

			return output;
		} // end of sum
		//------

		//------
		activate(inputs = [])
		{
			if(inputs.length !== this.weights.length){ throw new Error('input and weight shape mismatch'); }

			let output = 0;
			output = this.sum(inputs); //sum executes weighing + sum + bias

			// Neuron activation is based sigmoid function
			let result = this.activatorFn(output);

			return result;


		} // end of activate
		//------


	} // end of class Neuron
    //----------------------------------------------------------------------

    // const weight = 1;
    // const bias = 4;
    // const value = 2;
    // const n = new Neuron(weight,bias,Math.sigmoid);

    
    // console.log('Run neuron against inputs');
    // console.log( 'n.activate(value): ' + n.activate(value) );




    //-------------------------
	// COMMENTED TEMPORARILY
	
	// console.log('manually starting and defining neural network - start');

 //               ┌───────────────► HIDDEN LAYER NEURON 1 WEIGHT 1 
 //               │  ┌────────────► HIDDEN LAYER NEURON 1 WEIGHT 2 
 //               │  │  ┌─────────► HIDDEN LAYER NEURON 2 WEIGHT 1 
 //               │  │  │  ┌──────► HIDDEN LAYER NEURON 2 WEIGHT 2 
 //				  │	 │  │  │  ┌───► OUTPUT LAYER NEURON O WEIGHT 1 
 //				  │  │  │  │  │  ┌► OUTPUT LAYER NEURON O WEIGHT 2 
 //    const weights = [0, 1, 0, 1, 0, 1];
 //    const bias = [0,0,0];
 //    const activatorFunction = Math.sigmoid;
 //    const derivativeActFnc = null;
 //    const lossFnc = null;
 //    const network = new Network(weights, bias, activatorFunction, derivativeActFnc, lossFnc);

 //    const inputValues = [2, 3];
 //    console.log('Run neural network against inputs');
 //    console.log(network.query(inputValues));  
	
	// console.log('manually starting and defining neural network - end');
	
	//---------------------------------------------------------------
	// ##############################################################
	// NOT TESTED - START
	// ##############################################################


	let trainingData = {};

	// We apply an arbitrary shift amount (135 to weight, 66 to height) so our data 
	// is easier to deal with, typically you would shift based on the mean.
	//  Name, Weight (lbs), Height (in), Gender

	trainingData.whg = [
	  // { name: "Alice",   weight: 133,  height: 65, gender: F },
	  { name: "Alice",   weight: -2,  height: -1, gender: 1 },
	  // { name: "Bob",     weight: 160,  height: 72,  gender: M },
	  { name: "Bob",     weight: 25,  height: 6,  gender: 0 },
	  // { name: "Charlie", weight: 152,  height: 70,  gender: M },
	  { name: "Charlie", weight: 17,  height: 4,  gender: 0 },
	  // { name: "Diana",   weight: 120, height: 60, gender: F },
	  { name: "Diana",   weight: -15, height: -6, gender: 1 },
	];

	// //DEBUG DATA
	// trainingData.whg = [
	//   // { name: "Alice",   weight: 133,  height: 65, gender: F },
	//   { name: "Alice",   weight: -2,  height: -1, gender: 1 },
	// ];


	
	// Let's generate our training data in a machine-readable form
	const data = [];

	for (let row in trainingData.whg) 
	{
		data.push
		([
			// I1
			trainingData.whg[row].weight,
			// I2
			trainingData.whg[row].height,
		]);
	};

	// Let's generate our training "answer" data in a machine-readable form
	const answers = [];
	for (let row in trainingData.whg) 
	{
		answers.push(trainingData.whg[row].gender);
	}


	console.log('Create neural network');
	const nn = new Network(
		// weights
		[1, 1, 1, 1, 1, 1],
		// bias
		[0, 0, 0],
		// activation function
		Sigmoid,
		// derivitave function of our activation function
		DerivSigmoid,
		// loss function
		Math.meanSquaredError,
	);

	console.log('Train neural network', data, answers);
	nn.train(data, answers, 100001, 0.1)

	console.log('Is Emily a girl or a boy')
	console.log('Answer', nn.query([-7, -3]) * 100, '% chance of being a girl' );

	console.log('Is Frank a girl or a boy')
	console.log('Answer', nn.query([20, 2]) * 100, '% chance of being a girl');	
	
	
	// ##############################################################
	// NOT TESTED - END
	// ##############################################################	
	//---------------------------------------------------------------


  </script>
</body>

</html>
